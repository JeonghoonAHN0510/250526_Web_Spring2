[ WebCrawling ]
- 웹페이지에서 원하는 데이터를 수집하는 기술
- 웹페이지 구동원리
    1) 정적 페이지 : HTML 소스에 데이터가 있는 경우
       -> Jsoup 라이브러리
    2) 동적 페이지 : HTML 소스에 JS가 데이터를 넣어주는 경우
       -> Selenium 라이브러리
- 목적 : 데이터 수집, 데이터 분석, 업무 효율성 증가
- robots.txt : 웹사이트 경로에 있는 크롤링 접근 규칙 파일
    -> 웹페이지주소/robots.txt

[ Jsoup ]
1. 설치 : https://mvnrepository.com/
2. 주요메소드
    1) 크롤링할 URL의 HTML를 자바의 Document 객체로 가져오기
       -> Document document = Jsoup.connect( 크롤링할URL ).get();
    2) 특정한 마크업 가져오기
       -> Elements elements = document.select( "CSS선택자" );
    3) 마크업의 데이터 가져오기
       -> String text = element.text();
       -> String src = element.attr( "src" );